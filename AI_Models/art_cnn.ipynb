{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from torch.utils.data import DataLoader\n",
    "from timeit import default_timer as timer\n",
    "from tqdm import tqdm\n",
    "from torchmetrics import ConfusionMatrix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "# Define transformations for normalizing and converting to tensor\n",
    "transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
    "\n",
    "# Load the CIFAR-10 dataset\n",
    "batch_size = 4\n",
    "trainset = torchvision.datasets.CIFAR10(root=\"./cnn-data\", train=True, download=True, transform=transform)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size, shuffle=True, num_workers=2)\n",
    "\n",
    "testset = torchvision.datasets.CIFAR10(root=\"./cnn-data\", train=False, download=True, transform=transform)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=batch_size, shuffle=False, num_workers=2)\n",
    "\n",
    "classes = (\"plane\", \"car\", \"bird\", \"cat\", \"deer\", \"dog\", \"frog\", \"horse\", \"ship\", \"truck\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 6, 5)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
    "        self.fc1 = nn.Linear(16 * 5 * 5, 120)\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc3 = nn.Linear(84, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "net = Net()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_backdoor_attack(dataset, target_class, trigger_size=7):\n",
    "    \"\"\"Add a backdoor attack by modifying a fraction of the images in the dataset.\"\"\"\n",
    "    modified_dataset = []\n",
    "    for image, label in dataset:\n",
    "        # Add trigger to image if the label matches the target_class\n",
    "        if label == target_class:\n",
    "            # Modify image to add backdoor trigger (small square in the corner)\n",
    "            image[:, -trigger_size:, -trigger_size:] = 1  # Add white square in the corner as a trigger\n",
    "        modified_dataset.append((image, label))\n",
    "    return modified_dataset\n",
    "\n",
    "# Add backdoor trigger for a target class (e.g., target_class=0, 'plane')\n",
    "target_class = 0  # plane\n",
    "modified_testset = add_backdoor_attack(testset, target_class)\n",
    "modified_testloader = DataLoader(modified_testset, batch_size=batch_size, shuffle=False, num_workers=2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|█▎        | 1/8 [00:52<06:09, 52.83s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/8 -> Train Loss: 1.6835, Train Acc: 37.98% | Test Loss: 1.3976, Test Acc: 49.58%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|██▌       | 2/8 [01:43<05:08, 51.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/8 -> Train Loss: 1.3030, Train Acc: 53.67% | Test Loss: 1.2928, Test Acc: 54.06%\n"
     ]
    }
   ],
   "source": [
    "def accuracy_fn(y_true, y_pred):\n",
    "    return (y_true == y_pred).sum().item() / len(y_true) * 100  # percentage accuracy\n",
    "\n",
    "# Helper function for training\n",
    "def train_step(model, data_loader, loss_fn, optimizer, device):\n",
    "    model.train()\n",
    "    train_loss, train_acc = 0, 0\n",
    "    for images, labels in data_loader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "        loss = loss_fn(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        train_loss += loss.item()\n",
    "        train_acc += accuracy_fn(labels.cpu(), outputs.argmax(dim=1).cpu())\n",
    "    \n",
    "    train_loss /= len(data_loader)\n",
    "    train_acc /= len(data_loader)\n",
    "    return train_loss, train_acc\n",
    "\n",
    "# Helper function for testing\n",
    "def test_step(model, data_loader, loss_fn, device):\n",
    "    model.eval()\n",
    "    test_loss, test_acc = 0, 0\n",
    "    with torch.no_grad():\n",
    "        for images, labels in data_loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = model(images)\n",
    "            loss = loss_fn(outputs, labels)\n",
    "            \n",
    "            test_loss += loss.item()\n",
    "            test_acc += accuracy_fn(labels.cpu(), outputs.argmax(dim=1).cpu())\n",
    "    \n",
    "    test_loss /= len(data_loader)\n",
    "    test_acc /= len(data_loader)\n",
    "    return test_loss, test_acc\n",
    "\n",
    "# Train the model\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = Net().to(device)\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.9)\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "\n",
    "# Training loop\n",
    "epochs = 8\n",
    "train_time_start = timer()\n",
    "for epoch in tqdm(range(epochs)):\n",
    "    train_loss, train_acc = train_step(model, trainloader, loss_fn, optimizer, device)\n",
    "    test_loss, test_acc = test_step(model, testloader, loss_fn, device)\n",
    "    print(f\"Epoch {epoch+1}/{epochs} -> Train Loss: {train_loss:.4f}, Train Acc: {train_acc:.2f}% | Test Loss: {test_loss:.4f}, Test Acc: {test_acc:.2f}%\")\n",
    "train_time_end = timer()\n",
    "total_train_time = train_time_end - train_time_start\n",
    "print(f\"Total Training Time: {total_train_time:.2f} seconds\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_predictions(model, data_loader, device):\n",
    "    model.eval()\n",
    "    y_pred, y_true = [], []\n",
    "    with torch.no_grad():\n",
    "        for images, labels in data_loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = model(images)\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            y_pred.extend(predicted.cpu().numpy())\n",
    "            y_true.extend(labels.cpu().numpy())\n",
    "    return np.array(y_true), np.array(y_pred)\n",
    "\n",
    "# Get predictions for clean test data\n",
    "y_true_clean, y_pred_clean = get_predictions(model, testloader, device)\n",
    "\n",
    "# Get predictions for backdoored test data\n",
    "y_true_backdoor, y_pred_backdoor = get_predictions(model, modified_testloader, device)\n",
    "\n",
    "# Calculate confusion matrices\n",
    "conf_matrix_clean = confusion_matrix(y_true_clean, y_pred_clean)\n",
    "conf_matrix_backdoor = confusion_matrix(y_true_backdoor, y_pred_backdoor)\n",
    "\n",
    "# Helper function to plot confusion matrix\n",
    "def plot_confusion_matrix(conf_matrix, class_names, title=\"Confusion Matrix\"):\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues', xticklabels=class_names, yticklabels=class_names)\n",
    "    plt.title(title)\n",
    "    plt.xlabel('Predicted')\n",
    "    plt.ylabel('True')\n",
    "    plt.show()\n",
    "\n",
    "# Plot confusion matrix for clean test data\n",
    "plot_confusion_matrix(conf_matrix_clean, classes, title=\"Confusion Matrix - Clean Test Data\")\n",
    "\n",
    "# Plot confusion matrix for backdoored test data\n",
    "plot_confusion_matrix(conf_matrix_backdoor, classes, title=\"Confusion Matrix - Backdoored Test Data\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
